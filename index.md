---
layout: default
---

<img align="left" src="assets/images/Photo.jpeg" style="padding-right: 30px; padding-bottom: 30px;">
&nbsp;  
My name is Alex and I'm a researcher interested in neural program synthesis, applications of machine learning to software engineering, and related areas like neurosymbolic AI and natural language processing. 

I recently finished my Master's at Carnegie Mellon University's (CMU) School of Computer Science in the Artificial Intelligence and Innovation program where I was also a member of [Neulab](https://www.cs.cmu.edu/~neulab/index.html) where I was advised by [Professor Graham Neubig](http://www.phontron.com/). 

I am currently working at MIT's Computer Science and Artificial Intelligence Laboratory (CSAIL) with [Yoon Kim (MIT CSAIL)](https://people.csail.mit.edu/yoonkim/) and [Jie Chen (MIT-IBM Watson AI Lab)](https://jiechenjiechen.github.io/). 


&nbsp;  
&nbsp;  
&nbsp;  

# \~/Publications

Shypula A, Yin P, Lacomis J, Goues CL, Schwartz E, Neubig G. ["Learning to Superoptimize Real-world Programs."](https://arxiv.org/abs/2109.13498). Best Paper, ICLR 2022 [Deep Learning for Code Workshop](https://dl4c.github.io/).

# \~/CV and Contact

If you would like the most recent copy of my CV, you can locate it [here](assets/cv_shypula_2021_phd.pdf). 

You can reach me at shypula üë®‚Äçüíª mit üèîÔ∏è edu. 

# \~/Background 

<!-- The spark for me came when I was writing the malloc systems code for CMU's intro to system's course. It was highly error-prone, it required careful programming skill, and its performance relied on increasingly complex use of data structures from implicit lists, to linked lists, to binned linked-lists. Nevertheless, we had a large test suite that would estimate the performance of our storage allocator and provide feedback as if it were an RL environment. I wondered, "could an artificially intelligent agent learn to write code like this from scratch," re-discover classic data structures, and teach us something new? I thought it was compelling, becuase the agent would have to write programs to explain its choices, which would be more interpretable than, say, a black-box neural network.  -->

Programming is an extremely difficult and error prone task that takes many years of training and education to master: we need to create tools to lower the barriers-to-entry and democratize this amazing technology. I'm interested in how we can create machines that can write programs and design computer systems in ways that help engineers in their day-to-day work. They should help humans in their day-to-day programming tasks and every now, and then, teach us something new. 

<!-- Writing programs is a hard task for an AI system, because the discrete search space for programs is huge and sparse (due to the brittleness of syntax and sensitivity of semantics).  -->

I think AI on programming languages is interesting in relation to other domains like natural languages, because we can execute code and use static analysis tools on code. So, in relation to some of these other domains, we have rich representations and feedback mechanisms that we can leverage. Moreover, there may exist many tools developed by Programming Languages, Compilers, and Software Engineering community that may also both beneficial to designing these AI coding systems, possibly in ways that have not yet been conceived yet. Lastly, programs and logic are effective at computing certain kinds of things and are more interpretable than black box neural networks: they have interesting promise as components in interpretable and robust AI systems and possibly in tasks that require complex / multi-hop reasoning. 

<!-- On the path to get there, there are lots of super interesting and useful problems to explore in neural program synthesis / neural program modeling and software engineering.  -->

Before my research career, I majored in Business at NYU's Stern School of Business and studied Chinese. I loved learning Chinese, because for some reason as a kid, I thought it required some kind of superintelligence to learn: it taught me that discipline, a love of learning, and time are truly the ingredients to master anything. 


<!-- It was when I worked at IBM and saw the potential of deep learning to change our daily lives: from how we write programs, solve problems, and run drive-thrus, that I made the leap to devote my life to AI research and its applications. It has taken a lot of work, but I haven't looked back once.  -->

# \~/Other

Besides CS research, I like walking up big, tall, snowy things: some mountains on my list are (in increasing altidude) [Mt. Rainier](https://en.wikipedia.org/wiki/Mount_Rainier), [Denali](https://en.wikipedia.org/wiki/Denali), [Aconcagua](https://en.wikipedia.org/wiki/Aconcagua), and [Cho Oyu](https://en.wikipedia.org/wiki/Cho_Oyu). Here are [some photos](baker.md) of me doing a (very) stochastic gradient ascent on a practice rescue line in a crevasse on Mt. Baker. 

I also absolutely love coffee from all over the world, especially Panama and East Africa. 